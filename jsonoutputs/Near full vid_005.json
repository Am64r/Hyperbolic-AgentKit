[
  {
    "speaker": "Guest",
    "content": "Yeah, I I mean, I definitely not a decelerationist. I think I'm like the the way I see this is how like kind of through the sovereignty lens. Right? There's the user and and community like a I mean, when I say user owned, it also includes communities of people as well, right? So, because I think it's important to balance the individualism and kind of more of a community feel as well. And I think it's important that like right now, the way people's the acceleration is kind of movement is just like let's go, right? It doesn't matter how. Let's just like improve the technology. And it doesn't matter how it's gonna be applied. Right? And so, like that part, I don't agree with because I think like if we mismanage that then we gonna get into like concentration of power and kind of you know, and we know that power corrupts and this is gonna be absolute power so it will corrupt absolutely. Right? So we'll have like one or maybe like two entities which are like controlling intelligence. And through that, that are able to reprogram everyone. So, like I do think it's important to have this technology built in a way that is owned by everyone. And everyone can kind of keep everyone else in check. Right? Like if you have an agent on your side and and like it's you know, cryptographically, on your side, then if somebody else is trying to misuse this technology, which people will, like you have as much pretty much capabilities to protect yourself. Right? From this, and and you'll have more people and more more kind of capacity to protect. So like, we we go back into the blockchain side. You want more people on a good side, then on a bad side. But all have the same kind of level of of capabilities. Because if we only have like one or couple of parties that are able to do that, now we kind of screwed. <noise>"
  },
  {
    "speaker": "Andy",
    "content": "Yeah. So, what's to stop, what's to stop people, like I know for example, right now in California, there is like an AI law being discussed, about kind of like control. But what's to stop, in the similar way of like the space race, for going to the Moon, or for kind of getting uh nation states technology and space. Same way with crypto, where nation states kind of don't want to ban it, but don't want to, you know, some will accumulate, some won't. What's like, is there, uh, is there a way in which we police AI, that is fair and, uh, adhesive or like is is a part of its growth trajectory, without kind of like stalling the growth, or, how like how do you view the tragedy of the commons, question, which I'm sure you get a lot, uh, when when it comes to AI?"
  },
  {
    "speaker": "Guest",
    "content": "Yeah, I mean I definitely think just like a pure political regulation is not enough, and it's not gonna be effective, right? Because it it's actually just stifles innovation. I mean, we we familiar with it in crypto, right? Because like every time, by the time they figure out what to do with like this instrument. Right? We already invented 500 new instruments, because it's like oh, you want a package deal that, you know, repurchase itself, you know, three times a day, and, you know, shorts on the back end? It's like, what what is this? Like, like we just invented completely new instrument. Now somebody needs to go and like, analyze if this is like a security, or commodity, or whatever, an option, or future now. No, it just doesn't work like that. You need you need a new way of kind of modeling it, and it needs to be, it needs to be product first, it needs to be user first, right? And I think for many of those regulations, they are like, let's cover our ass, and let's like protect the government, versus like what is actually benefits the user. And so, so I think like with actually, Bitcoin, what you mentioned, right? Like some accumulate, right? And some, you know, maybe like not, and kind of trying to ban it, but at least that's an incentive mechanism. Right? Like, you know, some people see it, and so they'll benefit, because like in a long term, they were early on and so they were. So, I think like we need similar structure, where we have incentives, uh, to do good things and detect when bad things are done. And, you know, leverage the same technology, and kind of in a way, leverage the also kind of crypto cryptography, and other methodologies to protect it. So, to give you an example, right, that you know, uh, we have deep fakes. Right? They, you know, anybody can generate a fake video, fake, uh, fake image, fake audio now. And there is a very kind of straightforward, although hard to adopt, methodology, which is well, if you are a company, you should sign all the content you publish. If you are government, you should sign the content you publish, right? White House, actually at some point started signing videos they publish with cryptographic signature, because now you know, like it doesn't matter if they publish a deep fake, this is published from their respective, right, uh, or whatever. Like Elon Musk publish something, like it's it's Elon Musk signature, it's not the signature of whatever, uh, whoever is in that video. So, like we're recording this, we should like auto auto sign at the end the content. And now, like if anybody wants to look at this, you know, recording, they can see like oh, actually, Illia signed this, right? And this is like kind of here's the providence, et cetera. So, I think like part of it is also thinking through, okay, we're gonna be in a world where, you know, like, the traditional way of like, oh, I'm giving you a piece of paper and you can trust me because it has a stamp on it, doesn't work anymore. But we've been on this world for a while now. It's not a new world. We just kind of being like, lazy about, like, adopting technology to really deal with that. And AI is just like, boo kind of, putting it in an overdrive. But like you know, Photoshop, fake, documents, etcetera, all of this existed before. We just now can do it at like, way larger scale. And so, I think that's important to just understand we need to, we need to build systems and kind of our society operating system into this post-AI world now. And cryptography and crypto economics is the way to do it. It's like fundamental building blocks to build this, you know, kind of software, our society."
  },
  {
    "speaker": "Rob",
    "content": "I'm not super confident in the government to implement that standard. I think you're right, like, polit- pol- political regulation is not enough, we need cryptographic regulation. And that that sort of, that signature that we can put into any sort of content is an an example of cryptographic regulation, or verification that that that can be embedded. And then, I think there's further verification that can be taken on chain, by proving certain actions of AI agents. And and I think that's probably the way to stop any kind of like, rogue AI, from misaligning with its creator, individual, corporate, or otherwise. But that that gets really hairy, when smart contracts start deploying their own AI agents. And we sort of, it's sort of two or three steps removed from a human. Um. Oh, Yeah.  But then we start getting, way too many app chains without the proper interoperability. Then we have another podcast about it. <noise> Too many app chains. <noise> Every It's the agent chain, and then it's all like, it's all downhill from there. <noise> Yeah. <noise> We Really, it's been a pleasure, man. Thank you for coming on and sharing some time. I think I think it's a good place to wrap here. Uh, really fun conversation. And appreciate your insights. And I hope you enjoyed the time off. "
  },
  {
    "speaker": "Guest",
    "content": "Thanks, guys. Thanks. Thanks for having me. Cheers. Thanks, man."
  }
]