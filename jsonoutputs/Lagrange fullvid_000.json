[
  {
    "speaker": "Rob",
    "content": "GM, G Eigen, Bgrange. Another episode of the EigenLayer AVS series today with our good friend Ishmael from Lagrange and uh Ishmael, you’re no stranger to the show. So welcome back."
  },
  {
    "speaker": "Ishmael",
    "content": "I’m not. I I think I’ve been on the Rollup more than any other podcast and I will keep coming back. This is this is by far my uh my favorite place to discuss Lagrange and a lot of the interesting things we've been working on. You guys were early to Eigen, early to Lagrange, and I think you directionally everything you guys talk about comes true."
  },
  {
    "speaker": "Rob",
    "content": "I hope so and uh and yeah, I mean, this uh you know, i- if if the Rollup had a uh a Rollup Hall of Fame, I think you would be a first ballot. So"
  },
  {
    "speaker": "Ishmael",
    "content": "I appreciate that."
  },
  {
    "speaker": "Rob",
    "content": "Awesome! More zk uh coverage coming away uh Ishmael and Lagrange. You guys are obviously building a ZK coprocessor. One of the first AVSs on EigenLayer and uh some of the most stake allocated to your coprocessor. Congratulations. Um, And obviously, we're still very early to ZK and uh coprocessors in general. So Yeah."
  },
  {
    "speaker": "Ishmael",
    "content": "Yeah."
  },
  {
    "speaker": "Rob",
    "content": "Absolutely uh love the topic. Uh I'm glad that you're here uh to educate us and our community about it and uh let's let's dive in."
  },
  {
    "speaker": "Ishmael",
    "content": "Yeah. So we put together some slides, I know usually we keep it a little bit more free form, but there's a lot of really exciting developments that have been core to Lagrange over the last two years since the foundation of the company, and a lot of it has kind of come together into a synthesis very recently, of a direction that I think is unique in this space. And it's a direction that combines the work that we've done on ZK, with the work that we have done alongside EigenLayer. And this is a concept that very broadly I like to call the internet of proving. This basic idea that the future of zero knowledge is a large amount of independent applications that use ZK as part of different parts of their core function. So to make it very specific, state proofs for interrupt protocols, um uh uh ZK uh proofs for rollups, validity proofs for rollups, and then execution proofs for coprocessors. All of that, coming from one central point. Um, and so yeah, and so we'd like to talk about kind of this evolution of blockchain architectures as starting with the first generation of chains, the first the first chain, being Bitcoin, of a consensus based on proof of work. To the second generation that is this evolution to to proof of stake systems, where economic guarantees coming from the c- uh consensus validators were used and are used to produce blocks. Where the attestation, the chronology of a chain at some point in time and a fork choice rule over how uh uh a leader is able to propose a change that chronology from the execution of transactions, is core to producing the next um uh independently verifiable unit of that chain's history. And now we talk about this evolution towards a third generation architecture. And this is a proof-based future. This is a point where every block is not guaranteed safety by an economic guarantee of attestation. It's guaranteed safety by a proof. Where the pr- the block itself is composed of requests and verifications of proofs from other execution spaces or from other off-chain compute sources, and the actual validity of that block of the state transition function is also guaranteed by a proof. It is an essence, the use of ZK at all levels of the stack. This is what we think of as this third generation of blockchain architectures, and this is where Lagrange sits at the core, and what we talk about as this internet of proving. Coprocessors, ZK rollups, ZK interop, all of those together create this verifiable internet, this verifiable network of networks, of verifiable zero knowledge computes. I can keep going, but I don't know if you want to you want to ask anything."
  },
  {
    "speaker": "Rob",
    "content": "I Yeah. I mean, I I think I think you're setting the stage here, so I'm gonna try not to interrupt too much, but if I have any burning questions, I I will jump in."
  },
  {
    "speaker": "Ishmael",
    "content": "Perfect. Um, and so yeah, the we'd like to call this concept the internet of proving. It is basically as I was saying before, this idea that every application in crypto will use proofs for something. Some will use it for guaranteeing the validity of your execution space for a rollup. Some will use it for requesting heavy off-chain compute from a coprocessor, and some will use that for interrupt, for being able to access cross-chain state. And together, it forms this network of networks, where you have networks specializing in the computation of specific proofs and delivering those proofs to a variety of different um downstream partners. And so we we're very fortunate to have been one of the first companies to launch um on EigenLayer, and the first company to launch a ZK prover on EigenLayer. Our state committee product is delivering proofs now to Layer Zero, Acala, and Polymer. Um our coprocessor product is delivering proof the teams like Azuki, EtherFi, Gearbox, um and a number of other ones we've yet to announce that we're very excited for. Um, and very broadly we're launching a new train of of proving very soon related to some rollups that I can't share more about today, but expect some big things very soon. But at the core, every proof comes back from the same network of networks. Run at the core by top institutional operators, people like Coinbase, OKX, Kraken, who are generating proofs across every single domain of the space, all from one unified substrate."
  },
  {
    "speaker": "Ishmael",
    "content": "And so the question that people always ask us is, why why EigenLayer? Why would you use EigenLayer as this place for economic security and staking to generate zero knowledge proofs? Um, you know, do you not need economic security for generating zero knowledge proofs? This is a very common question I'm asked. But let's take a step back for a minute. At the core, what a proof is able to do is guarantee the safety of a computation. So you can say I don't have to trust Ishmael to give me the correct computation over some data for the coprocessor. I don't have to trust Ishmael to give some computation over data for this cross-chain state, or for a validity proof for a rollup. All I have to do is verify the proof. But what you still have to trust even with the proof is that I'll actually give you the proof. The liveness of the delivery of that proof is not guaranteed. So if your application needs a validity proof or a coprocessor proof, or a state proof at a certain point of time to underwrite some state transition or some specific action, you still need to guarantee that you will get it when you requested it. And that's this concept of liveness within blockchains, within pro-networks, within zero knowledge systems, more broadly. The way we guarantee that is through stake. And the way we get that stake with the lowest cost of capital and the most favorable cost structure in crypto, is through restaking. Um, very complex prover needs can be met very succinctly and very simply by using the core Lagrange prover network, prover market, which is in effect just a network of more networks. It's the internet of proving."
  },
  {
    "speaker": "Ishmael",
    "content": "And so to make this very concrete, you know, how does this work? Well, at a very high level, when you want a proof you request it from what we call a gateway. A gateway is able to manage the relationship between a proof requester and a- a pool of provers who will compute those proofs based on demand. That gateway announces a new prover task or a group of prover tasks to all provers who have subscribed to generating a certain uh topic of proofs. And those provers bid on uh the ability to generate those proofs. This is through a novel paper called double auctions for dynamic resource resource allocation that our team has come up with. Um, that is to our knowledge and to our belief, the first and the only incentive compatible structure for um for pricing of proofs in a heterogeneous resource market within a prover network. Um, if the operator generates the proof on time within a given time slot, they receive their proof payment, they receive a fee um for generating that proof. And if they fail to generate the proof, they receive a penalty. You can think of this very much like a block validation, right? If you're a Ethereum validator, you have a slot under which you can execute an attestation, or propose a block. Um, and if you don't meet your requirements, you face an economic penalty. Except what we're talking about here is not a signature or a validation action. We're talking about the generation of proof."
  }
]