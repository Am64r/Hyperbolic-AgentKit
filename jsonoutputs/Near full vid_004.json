[
  {
    "speaker": "Rob",
    "content": "abilities that can be used to do something bad, right? AI is actually getting better and better at detecting these vulnerabilities because it's seeing all the code and it's seeing vulnerabilities so it can actually kind of match really well. Uh, I did actually run the test myself and found like vulnerability in some go uh, compiler. And what will happen is like if this continues and we don't fix it, we actually going to have more and more hacks, right, happening. Now, in crypto we actually been working on this because we have the situation where a lot of money are at stake and we need to actually have very correct code. And so we have been working on formal verification research for this specific reason. And so the kind of one of the dimensions of work we're doing is how to use AI to do formal verification. And smart contracts is the first use case kind of the because it's like straightforward and valuable and uh, and this is but this is a way we believe kind of all the future software will be built, is it will be built by AI with formal proofs. And formal proofs have this like nice kind of similar to ZK, uh, proves property that, you know, if you have some requirements and you're using some other code which has a formal proof if it doesn't match if there is something incorrect there, it will just not like proo- proof will not be correct, right? You cannot plug it in. So, so all of that like pieces you know piecing all this together kind of the vision is really to a half an open source kind of user owned AI ecosystem uh, it's going to be lots of different projects coming together competing, you know, providing different properties and, you know, at the end benefiting the user. Again sovereignty in the hands of the user. Uh, and then one of those use cases will be an ability for user to build software without writing code. And so that's kind of uh, research we're working on. But what this enables now is completely new experiences, right? Where, you know, the chain abstraction will be it will be like next level from chain abstraction, right? Now you can abstract user interfaces as well where you can on a fly generate a front end that, you know, interact with multiple chains, with multiple, you know, APIs etcetera and gives you the experience that you want at this moment. And so you can imagine, you know, even predicting that you want to interact with something and kind of generating that on a fly. Or you saying like, hey, actually I want to do this right now. Boom, you have this custom front end. So, we have few projects that are working on different angles of that, right? Like for DeFi specifically like hey can we like combine all the front ends, can we have chain signatures together, boom, now you have this AI can like navigate that and uh, and you know initiate transactions. Like initiate transactions with the AI initiating uh, kind of interactions, etcetera. So, all of that is in progress like in different versions so we can like start to see how it will work uh, as it ties together. Again, it's kind of one level above of a chain abstraction where, you know, you kind of abstract in the whole computing with uh, natural language. But chain abstraction serves as a big function of that because we do need to move to a more trustless kind of world and that will be the big fundamental piece to power that. I just went on like a 10 minute rant I think so. Yeah, I mean, is uh, just real quick couple things. Um, I feel like, like some of these companies wo- that are like compa- companies that are charg- charging for services that can use AI are going to have to like kind of shift their business models or like figure how to incorporate AI to, and keep an edge. You mentioned audits um, a- and some, some of these other kind of areas so I think that's interesting. I also think how you mentioned that's like, NEAR in particular is set up for the expansion of AI based on how you're ho- how your blockchain is built. It will be very interesting to see how other kind of, types of companies accelerate more than others with the use of AI and kind of which adopt it a- and kind of instead of shying away, really kind of like embrace it. Uh, those are my two first main points but yeah, Rob would love to get some esoteric entropy based takes here."
  },
  {
    "speaker": "Guest",
    "content": "I, I love the idea of user owned AI. I think there's issues with the AI programs that we've seen out there now and they're owned by corporations and they're operating based on the interests of these corporations that are profit seeking and they're they, they've shown behavior of preying on their users and and extracting value from them. So the idea of user owned AI I think makes a ton of sense. And I'm I'm very curious to see how the incentive model will change um, when we have these AI agents that are acting on our behalf. Um, maybe they have, I, I, I think, I think these AI agents end up having these, these uh, the value that I can provide uh, is going to end up for, okay so, zooming out. I think one the, there has to be an incentive for some platform because people aren't going to have the, the technical knowledge to deploy their own AI. So there's going to have to be some GPT model type platform that will allow them to, to deploy their own AI agent. And then it's a matter of how they want to optimize it and that that will be the specialized value that it provides to other AI agents. Um, and then how those AI agents interact with these closed source corporate owned ones. I think, there, there's this alignment problem or potential, potential problem. Where um, like for one, how do I make sure, I think it's pretty obvious that my AI, my interests are not totally aligned with the corporation. And so if the if the corporation deploys the AI, my interests aren't aligned with that agent, if it's acting in the best interest of the corporation. But what if we have like this, this extrapolate to the end user but what, let's just start with two corporations, right? That each have their own AI agents and maybe they have contradictory interests. What's to say that, that one isn't able to convince, my AI agent isn't able to convince your AI agent to like, do something in my best interest rather than your best interest. I, I think those natural competitions are going to evolve and and how those things come out, I think it's going to be really really cool to, to see. Because we're going to end up with these AI agent competitions. Um, and I think we're hearing a lot about uh, so I think user owned AI to, once I have my user competing against other users. Um, there's going to be a very natural like, healthy competition of like, me specializing in one thing, providing value to your AI agent, paying, AI agents paying one another to do that, and there's going to be a whole economy that emerges as a result of that. And I think it's natural for that to happen, especially when it's user owned for that to happen on blockchains because it's already a natural place for economies to emerge, especially for open source, uh, technology and and incentives."
  },
  {
    "speaker": "Rob",
    "content": "Well, and in general like AI agents have trouble like, doing finance which is not on blockchain. So, it's just like so much more straightforward to plug them in into an account and then have tran- them transacting then doing that with Stripe or with like any other infrastructure. And like you can start them, they can be like, you know, semi autonomous, they can raise their own money potentially right by launching a token. And like pay their suppliers, like they can do all this work and you know, like you can go from this is my agent to like, this is a fully autonomous agent that just raised it's own money and now, you know, providing a service as like uh, you know, and monetizing it and redistributing profits to the, to the token holders and it's not a security because it's not controlled by anyone. You think it's like, still aligned with the, the entity that deploys it? Or do you think it is totally autonomous? But it needs to be yeah it, it can be like completely autonomous. Um, and so like you have, you know we ha-, we building enough infrastructure so that like the, you can trigger a lamb from on chain right, you pay for that on chain, and so you can have a smart contract that literally does all that and kind of if, if it have enough money it will be able to do it. If it ru-, if it mismanages its money, you know it's it's done. Uh, and, yeah I mean you want to have some oversight so like token holders can have governance power, they can provide feedback, they can provide training data for this AI agent. Uh, and actually pitched this idea is like, AI CEO, right? So, you have like AI that, you have a board members or you know token holders who can like vote on you know what is doing well and and not but then it actually goes and executes day to day, you know, does like day to day work."
  },
  {
    "speaker": "Andy",
    "content": "Yeah. In the extreme case that looks like AI president, but in the less extreme case, that I think is, is somewhat, I've heard this idea where these AI, these AI accelerationists are trying to basically, come up with an AI or, AGI. And then, if it if it, the AI for the company, or the corporation then you just ask it, you just ask it how to, how do we optimize for revenue? Right? And you, you generate the AGI and then you use it to to basically be the CEO of the company. You, are you, are you one of these accelerationists, or a decelerationists? How do you philosophically view this?"
  }
]