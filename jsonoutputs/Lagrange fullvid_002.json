[
  {
    "speaker": "Andy",
    "content": "Prover network has very high uh operational costs. The amount of hardware that's required, the the complexity of running that hardware are much higher. That said, because stake is only being used to guarantee liveness, the amount that's being paid to stake is going to be much lower, because the stake is not at risk to the same extent that it is in a POS chain. And so, the way the network works is that to your point earlier user requests a proof from the co-processor, from the state committees, or from one of the other things we're announcing soon. And from there, you're able to from there"
  },
  {
    "speaker": "Andy",
    "content": "Like that face. From there, you're able to um uh uh pay a fee to the network to receive that proof. And that's generally through a contract that emits an event or through just a direct request from one of the gateways. When that proof is generated and delivered back, um uh uh the prover is remunerated for that. And the amount the prover receives is proportionate to what they bid. So the profit margin on a prover depends on what they run, what hardware they run. And this is why over time these market-based designs converge back to having substantially lower um uh uh cost than oftentimes just a a a SaaS or a cloud-based uh proving service. Because the incentive is on every operator to optimize their costs. Where if you can underbid everyone else by 1 cent and still maintain a profit margin of 50%, that's a very great economic incentive for you to be in economic position for you to be in. There is a a an incentive to optimize provers by someone the scientists, the core team, in order to be able to increase the profit margin on generating these. And you know, if we talk about the size of the proving market right now, it's about 150 million from our our predict from our assessment annually, if we look at rollups, co-processors, state proofs, in terms of the amount being spent generally on cloud now and compute costs. And there's a a very large pie available for anyone who can take existing implementations of a lot of these provers, optimize them, and increase their profit margin. And a market and an auction that assigns work based on bids is the best way to allow people to capture that value, and to create positive externalities over cheaper cost and better performance, re- re- resulting in um material uh material revenue, material profit for operators."
  },
  {
    "speaker": "Rob",
    "content": "Awesome. Okay. Yeah, I mean, that that makes sense and just kind of like uh, I guess briefly kind of characterize this, like, you know, this this is a stark transition from that of like a Proof of Stake or Tendermint chain, which has relatively low operational cost, just to run a few validators, but a very high capital cost, and in the range of 10 to 15%, paying for that for that economic security. Whereas, uh uh uh an AVS, and particularly a zkAVS, um has a very low capital cost due to re-staking, but a very high operational cost per task um uh uh for each of these proofs that are getting generated. Now, um you know, one of the quick quick quick tangent, which is that a while ago, we were doing one of these we were doing one of these episodes. And it was, you know, everything moves so fast in this industry. And so at the time, I think, you know, you guys were working on your prover, and there was another entity that had undergone some sort of transition. They were doing a prover, uh but then they ended up going more into the prover network, uh realm. And at the time you had told me like, you know, you guys are focused on the real ZK, right, which is those who are are building uh uh building the provers, the ones the the right? And maybe going into prover network was almost like an easy way out.  Is there, like, a new is there new evidence that kind of supports prover networks and like lowering the operational cost dramatically or is are the prover networks mostly just like a I mean generally, how do you reconcile like this, you know, the doing a prover network versus being one of those entities that is helping to uh generate those proofs via either uh a zkVM or a circuit?"
  },
  {
    "speaker": "Andy",
    "content": "Yeah. Yes."
  },
  {
    "speaker": "Andy",
    "content": "Yeah."
  },
  {
    "speaker": "Andy",
    "content": "Yeah, this is this is this is a great this is a great um comment. So very broadly, Lagrange builds a co-processor. We build a a prover that we use to verify arbitrary SQL computation um over blockchain data. That's kind of the core function of our co-processor. Um you can write any type of SQL statement that you'd want to run. We can parse that SQL statement and what's called an abstract syntax tree. We can prove that computation over data. And so that is one of the core things that's deployed on top of our network. The second core thing that's deployed is our state committees. And state committees are state proofs for for rollups, for for state proofs generated from optimistic rollups, like a fast pre-confirmation, design essence, that we distribute through a lot of our cross-chain partners. Um and so both of those are kind of core products that we we we build. And so the imperative on those two core products to have a network that underpins them, that can guarantee liveness on delivering those. Right? So you know, Azuki uses our prover. Etherfi uses our prover, Gearbox uses our prover. Um a number of other DeFi protocols will announce soon. Use our prover um just as, you know, Acala, Polymer, LayerZero use use state proofs for their VM in in LayerZero. We have an integration with Polymer, and Acala. We're part of their we're going to be soon part of their cross-chain um uh amplifier protocol. And so the question of, you know, why would you use a prover network comes down to do you feel that there is a reason to build one yourself versus do you think there is reason to deploy on another one? And so we have a very bespoke architecture that we that we um have been working with some of our very close partners on, that we think has very accretive economics overall for their design. And so as we've increased building our own product along the lines of our zk co-processor and our state committees, there's certain things that our team has built that are actually very extensible for other teams. So, you know, building a a production-grade decentralized auction for resource allocation, in a dynamically and horizontally scalable network is complex. And we've found that, you know, while it is not complex to spin up a couple of EWS instances and call yourself a proving network, it is very complex if you want incentive compatibility, resource pricing, and a very robust and dynamic set of institutional operators, maintaining that operator base, ensuring they have the right upgrade path, ensuring they have the right binaries to running, ensuring participating properly. All of that stuff is a very large overhead. And so there's some teams that we've that we've spent time with um, who have started to feel that that that being able to move some of that onto a network that's already generating proofs and production for a variety of other applications, is is beneficial for them. But broadly speaking, I'm actually kind of bearish on these general concepts of proving networks, because I I I don't think you you really need um you really need a company that just builds network, a network. Um if that network is not fundamentally differentiated in what they can offer to you. Um and if the economics of that network aren't aren't beneficial to you. So to make that very concrete, you know, let's say, you know, there's there's the Robby proving network, and it has Robby token. Um and I let's say I have a proving demand about 10 million dollars a year for for let's say all of my products. Um, would I route all 10 million dollars of my fees per year to Robby's network and Robby's token? Likely not. It just doesn't make sense. But if someone came to me and they said, “Hey, you know, it's my own, um we'll build the whole proven network for you. We'll build the auction for you, and we want nothing.” Would I do it? Yeah, obviously I'd save I'd save a lot of money. So there's something in the middle between the network takes nothing and the current design of these networks, which are these giant monolithic basically POS chains, with some provers plugged into them to try to take everything. Right? The the left side has taken has gotten no PMF. And the right side means a very, very high overhead for everyone to build things. Right? It means that when Lagrange said in, you know, in May or or maybe April, “Hey, you know, we want to be able to have a network to deliver our proofs for our customers, so they can trust they get there on time, so they can trust this liveness. There's no option but to build it ourselves otherwise we lose all of our revenue or build it ourselves.” I I I think that architectures like what we have and we'll have a lot more public on docs very soon, they they find the middle ground. They let teams maintain sovereignty and agency over what they're doing. The same way that we maintain sovereignty and agency over our proofs within our network. But they do so in a way that that makes it a actually very reasonable decision to underwrite moving your proving onto an external network. And this is why we kind of talk about this “Internet of Proving” or this “Network of Networks,” because it really isn't you deploying on Lagrange's network. It's you deploying a network that mimics an architecture that Lagrange has, much like a rollup. Right? You deploy an Optimism rollup but it's still based. Right? You deploy a a optimistic rollup but, you know, it might be on the Arbitrum stack. You can deploy uh uh uh what we call a Supernet, that that benefits from all of the things that we've talked about in the production-grade infrastructure to run your prover on that exists within the broader context of our Internet of Proving or INP. "
  }
]